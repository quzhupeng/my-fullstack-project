#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿ
ç‰ˆæœ¬: 1.0
ä½œè€…: Kilo Code
æ—¥æœŸ: 2025-01-05

åŠŸèƒ½:
1. å®æ—¶æ•°æ®è´¨é‡ç›‘æ§
2. å¼‚å¸¸æ£€æµ‹å’Œå‘Šè­¦
3. æ•°æ®è´¨é‡æŠ¥å‘Šç”Ÿæˆ
4. è‡ªåŠ¨åŒ–è´¨é‡æ£€æŸ¥
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
import json
import os
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('data_quality_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class QualityIssue:
    """æ•°æ®è´¨é‡é—®é¢˜æ•°æ®ç±»"""
    issue_type: str
    severity: str  # 'low', 'medium', 'high', 'critical'
    description: str
    affected_records: int
    table_name: str
    column_name: str
    detection_time: str
    suggested_action: str

@dataclass
class QualityMetrics:
    """æ•°æ®è´¨é‡æŒ‡æ ‡æ•°æ®ç±»"""
    completeness_score: float
    accuracy_score: float
    consistency_score: float
    validity_score: float
    overall_score: float
    total_records: int
    valid_records: int
    issue_count: int

@dataclass
class QualityReport:
    """æ•°æ®è´¨é‡æŠ¥å‘Šæ•°æ®ç±»"""
    report_id: str
    timestamp: str
    metrics: QualityMetrics
    issues: List[QualityIssue]
    recommendations: List[str]
    data_sources: List[str]
    processing_time: float

class DataQualityMonitor:
    """æ•°æ®è´¨é‡ç›‘æ§å™¨"""
    
    def __init__(self, excel_folder: str = './Excelæ–‡ä»¶å¤¹/'):
        self.excel_folder = excel_folder
        self.logger = logging.getLogger(f"{__name__}.DataQualityMonitor")
        
        # è´¨é‡é˜ˆå€¼é…ç½®
        self.quality_thresholds = {
            'excellent': 0.95,
            'good': 0.85,
            'acceptable': 0.70,
            'poor': 0.50
        }
        
        # å¼‚å¸¸æ£€æµ‹å‚æ•°
        self.anomaly_params = {
            'z_score_threshold': 3.0,
            'iqr_multiplier': 1.5,
            'ratio_min': 0,
            'ratio_max': 200,
            'volume_min': 0,
            'volume_max': 1000000
        }
        
        # æ•°æ®æºé…ç½®
        self.data_sources = {
            'sales': 'é”€å”®å‘ç¥¨æ‰§è¡ŒæŸ¥è¯¢.xlsx',
            'inventory': 'æ”¶å‘å­˜æ±‡æ€»è¡¨æŸ¥è¯¢.xlsx',
            'production': 'äº§æˆå“å…¥åº“åˆ—è¡¨.xlsx'
        }
    
    def run_quality_check(self) -> QualityReport:
        """è¿è¡Œå®Œæ•´çš„æ•°æ®è´¨é‡æ£€æŸ¥"""
        start_time = datetime.now()
        self.logger.info("å¼€å§‹æ•°æ®è´¨é‡æ£€æŸ¥...")
        
        try:
            # åŠ è½½æ‰€æœ‰æ•°æ®æº
            datasets = self._load_all_datasets()
            
            # æ‰§è¡Œè´¨é‡æ£€æŸ¥
            all_issues = []
            all_metrics = []
            
            for source_name, df in datasets.items():
                if df is not None and not df.empty:
                    issues, metrics = self._check_dataset_quality(df, source_name)
                    all_issues.extend(issues)
                    all_metrics.append(metrics)
            
            # è®¡ç®—æ•´ä½“è´¨é‡æŒ‡æ ‡
            overall_metrics = self._calculate_overall_metrics(all_metrics)
            
            # ç”Ÿæˆå»ºè®®
            recommendations = self._generate_recommendations(all_issues, overall_metrics)
            
            # åˆ›å»ºæŠ¥å‘Š
            processing_time = (datetime.now() - start_time).total_seconds()
            report = QualityReport(
                report_id=f"QR_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                timestamp=datetime.now().isoformat(),
                metrics=overall_metrics,
                issues=all_issues,
                recommendations=recommendations,
                data_sources=list(datasets.keys()),
                processing_time=processing_time
            )
            
            self.logger.info(f"æ•°æ®è´¨é‡æ£€æŸ¥å®Œæˆï¼Œè€—æ—¶ {processing_time:.2f} ç§’")
            return report
            
        except Exception as e:
            self.logger.error(f"æ•°æ®è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
            raise
    
    def _load_all_datasets(self) -> Dict[str, pd.DataFrame]:
        """åŠ è½½æ‰€æœ‰æ•°æ®é›†"""
        datasets = {}
        
        for source_name, filename in self.data_sources.items():
            try:
                filepath = os.path.join(self.excel_folder, filename)
                if os.path.exists(filepath):
                    df = pd.read_excel(filepath)
                    datasets[source_name] = df
                    self.logger.info(f"åŠ è½½ {source_name} æ•°æ®: {len(df)} æ¡è®°å½•")
                else:
                    self.logger.warning(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                    datasets[source_name] = None
            except Exception as e:
                self.logger.error(f"åŠ è½½ {source_name} æ•°æ®å¤±è´¥: {e}")
                datasets[source_name] = None
        
        return datasets
    
    def _check_dataset_quality(self, df: pd.DataFrame, source_name: str) -> Tuple[List[QualityIssue], QualityMetrics]:
        """æ£€æŸ¥å•ä¸ªæ•°æ®é›†çš„è´¨é‡"""
        self.logger.info(f"æ£€æŸ¥ {source_name} æ•°æ®è´¨é‡...")
        
        issues = []
        
        # 1. å®Œæ•´æ€§æ£€æŸ¥
        completeness_issues, completeness_score = self._check_completeness(df, source_name)
        issues.extend(completeness_issues)
        
        # 2. å‡†ç¡®æ€§æ£€æŸ¥
        accuracy_issues, accuracy_score = self._check_accuracy(df, source_name)
        issues.extend(accuracy_issues)
        
        # 3. ä¸€è‡´æ€§æ£€æŸ¥
        consistency_issues, consistency_score = self._check_consistency(df, source_name)
        issues.extend(consistency_issues)
        
        # 4. æœ‰æ•ˆæ€§æ£€æŸ¥
        validity_issues, validity_score = self._check_validity(df, source_name)
        issues.extend(validity_issues)
        
        # è®¡ç®—æ•´ä½“è´¨é‡åˆ†æ•°
        overall_score = (completeness_score + accuracy_score + consistency_score + validity_score) / 4
        
        metrics = QualityMetrics(
            completeness_score=completeness_score,
            accuracy_score=accuracy_score,
            consistency_score=consistency_score,
            validity_score=validity_score,
            overall_score=overall_score,
            total_records=len(df),
            valid_records=len(df) - len([i for i in issues if i.severity in ['high', 'critical']]),
            issue_count=len(issues)
        )
        
        return issues, metrics
    
    def _check_completeness(self, df: pd.DataFrame, source_name: str) -> Tuple[List[QualityIssue], float]:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        issues = []
        
        # æ£€æŸ¥ç©ºå€¼
        null_counts = df.isnull().sum()
        total_cells = len(df) * len(df.columns)
        null_cells = null_counts.sum()
        
        for column, null_count in null_counts.items():
            if null_count > 0:
                severity = self._determine_severity(null_count / len(df))
                issues.append(QualityIssue(
                    issue_type="missing_data",
                    severity=severity,
                    description=f"åˆ— '{column}' æœ‰ {null_count} ä¸ªç©ºå€¼",
                    affected_records=null_count,
                    table_name=source_name,
                    column_name=column,
                    detection_time=datetime.now().isoformat(),
                    suggested_action=f"æ£€æŸ¥ {column} åˆ—çš„æ•°æ®å½•å…¥æµç¨‹"
                ))
        
        # è®¡ç®—å®Œæ•´æ€§åˆ†æ•°
        completeness_score = max(0, (total_cells - null_cells) / total_cells) if total_cells > 0 else 0
        
        return issues, completeness_score
    
    def _check_accuracy(self, df: pd.DataFrame, source_name: str) -> Tuple[List[QualityIssue], float]:
        """æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§"""
        issues = []
        accuracy_violations = 0
        total_checks = 0
        
        # æ£€æŸ¥æ•°å€¼åˆ—çš„åˆç†æ€§
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        
        for column in numeric_columns:
            total_checks += len(df)
            
            # æ£€æŸ¥è´Ÿå€¼ï¼ˆå¯¹äºåº”è¯¥ä¸ºæ­£çš„å­—æ®µï¼‰
            if column in ['ä¸»æ•°é‡', 'å…¥åº“', 'å‡ºåº“', 'å•ä»·']:
                negative_count = (df[column] < 0).sum()
                if negative_count > 0:
                    accuracy_violations += negative_count
                    issues.append(QualityIssue(
                        issue_type="invalid_value",
                        severity="high",
                        description=f"åˆ— '{column}' æœ‰ {negative_count} ä¸ªè´Ÿå€¼",
                        affected_records=negative_count,
                        table_name=source_name,
                        column_name=column,
                        detection_time=datetime.now().isoformat(),
                        suggested_action=f"æ£€æŸ¥ {column} åˆ—çš„æ•°æ®å½•å…¥ï¼Œè´Ÿå€¼å¯èƒ½ä¸åˆç†"
                    ))
            
            # æ£€æŸ¥å¼‚å¸¸å¤§çš„å€¼
            if len(df[column].dropna()) > 0:
                q99 = df[column].quantile(0.99)
                extreme_values = (df[column] > q99 * 10).sum()
                if extreme_values > 0:
                    accuracy_violations += extreme_values
                    issues.append(QualityIssue(
                        issue_type="outlier",
                        severity="medium",
                        description=f"åˆ— '{column}' æœ‰ {extreme_values} ä¸ªæç«¯å€¼",
                        affected_records=extreme_values,
                        table_name=source_name,
                        column_name=column,
                        detection_time=datetime.now().isoformat(),
                        suggested_action=f"æ£€æŸ¥ {column} åˆ—çš„æç«¯å€¼æ˜¯å¦æ­£ç¡®"
                    ))
        
        # è®¡ç®—å‡†ç¡®æ€§åˆ†æ•°
        accuracy_score = max(0, (total_checks - accuracy_violations) / total_checks) if total_checks > 0 else 1.0
        
        return issues, accuracy_score
    
    def _check_consistency(self, df: pd.DataFrame, source_name: str) -> Tuple[List[QualityIssue], float]:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        issues = []
        consistency_violations = 0
        total_checks = 0
        
        # æ£€æŸ¥é‡å¤è®°å½•
        if len(df) > 0:
            duplicate_count = df.duplicated().sum()
            total_checks += len(df)
            
            if duplicate_count > 0:
                consistency_violations += duplicate_count
                issues.append(QualityIssue(
                    issue_type="duplicate_records",
                    severity="medium",
                    description=f"å‘ç° {duplicate_count} æ¡é‡å¤è®°å½•",
                    affected_records=duplicate_count,
                    table_name=source_name,
                    column_name="all",
                    detection_time=datetime.now().isoformat(),
                    suggested_action="åˆ é™¤é‡å¤è®°å½•æˆ–æ£€æŸ¥æ•°æ®å½•å…¥æµç¨‹"
                ))
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼ä¸€è‡´æ€§
        text_columns = df.select_dtypes(include=['object']).columns
        for column in text_columns:
            if column in df.columns:
                # æ£€æŸ¥ç©ºå­—ç¬¦ä¸²å’Œç©ºæ ¼
                empty_strings = (df[column].astype(str).str.strip() == '').sum()
                total_checks += len(df)
                
                if empty_strings > 0:
                    consistency_violations += empty_strings
                    issues.append(QualityIssue(
                        issue_type="format_inconsistency",
                        severity="low",
                        description=f"åˆ— '{column}' æœ‰ {empty_strings} ä¸ªç©ºå­—ç¬¦ä¸²",
                        affected_records=empty_strings,
                        table_name=source_name,
                        column_name=column,
                        detection_time=datetime.now().isoformat(),
                        suggested_action=f"æ ‡å‡†åŒ– {column} åˆ—çš„æ•°æ®æ ¼å¼"
                    ))
        
        # è®¡ç®—ä¸€è‡´æ€§åˆ†æ•°
        consistency_score = max(0, (total_checks - consistency_violations) / total_checks) if total_checks > 0 else 1.0
        
        return issues, consistency_score
    
    def _check_validity(self, df: pd.DataFrame, source_name: str) -> Tuple[List[QualityIssue], float]:
        """æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§"""
        issues = []
        validity_violations = 0
        total_checks = 0
        
        # æ£€æŸ¥ä¸šåŠ¡è§„åˆ™
        if 'ç‰©æ–™åç§°' in df.columns:
            total_checks += len(df)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«åº”è¯¥è¿‡æ»¤çš„äº§å“
            fresh_products = df[df['ç‰©æ–™åç§°'].str.contains('é²œ', na=False)]
            if len(fresh_products) > 0:
                validity_violations += len(fresh_products)
                issues.append(QualityIssue(
                    issue_type="business_rule_violation",
                    severity="medium",
                    description=f"å‘ç° {len(fresh_products)} ä¸ªé²œå“è®°å½•ï¼ˆåº”è¢«è¿‡æ»¤ï¼‰",
                    affected_records=len(fresh_products),
                    table_name=source_name,
                    column_name="ç‰©æ–™åç§°",
                    detection_time=datetime.now().isoformat(),
                    suggested_action="æ£€æŸ¥ä¸šåŠ¡è¿‡æ»¤è§„åˆ™æ˜¯å¦æ­£ç¡®åº”ç”¨"
                ))
        
        # æ£€æŸ¥æ—¥æœŸæœ‰æ•ˆæ€§
        date_columns = df.select_dtypes(include=['datetime64']).columns
        for column in date_columns:
            total_checks += len(df)
            
            # æ£€æŸ¥æœªæ¥æ—¥æœŸ
            future_dates = (df[column] > datetime.now()).sum()
            if future_dates > 0:
                validity_violations += future_dates
                issues.append(QualityIssue(
                    issue_type="invalid_date",
                    severity="high",
                    description=f"åˆ— '{column}' æœ‰ {future_dates} ä¸ªæœªæ¥æ—¥æœŸ",
                    affected_records=future_dates,
                    table_name=source_name,
                    column_name=column,
                    detection_time=datetime.now().isoformat(),
                    suggested_action=f"æ£€æŸ¥ {column} åˆ—çš„æ—¥æœŸå½•å…¥"
                ))
        
        # è®¡ç®—æœ‰æ•ˆæ€§åˆ†æ•°
        validity_score = max(0, (total_checks - validity_violations) / total_checks) if total_checks > 0 else 1.0
        
        return issues, validity_score
    
    def _determine_severity(self, ratio: float) -> str:
        """æ ¹æ®æ¯”ä¾‹ç¡®å®šé—®é¢˜ä¸¥é‡ç¨‹åº¦"""
        if ratio >= 0.5:
            return "critical"
        elif ratio >= 0.2:
            return "high"
        elif ratio >= 0.05:
            return "medium"
        else:
            return "low"
    
    def _calculate_overall_metrics(self, metrics_list: List[QualityMetrics]) -> QualityMetrics:
        """è®¡ç®—æ•´ä½“è´¨é‡æŒ‡æ ‡"""
        if not metrics_list:
            return QualityMetrics(0, 0, 0, 0, 0, 0, 0, 0)
        
        # åŠ æƒå¹³å‡ï¼ˆæŒ‰è®°å½•æ•°åŠ æƒï¼‰
        total_records = sum(m.total_records for m in metrics_list)
        
        if total_records == 0:
            return QualityMetrics(0, 0, 0, 0, 0, 0, 0, 0)
        
        weighted_completeness = sum(m.completeness_score * m.total_records for m in metrics_list) / total_records
        weighted_accuracy = sum(m.accuracy_score * m.total_records for m in metrics_list) / total_records
        weighted_consistency = sum(m.consistency_score * m.total_records for m in metrics_list) / total_records
        weighted_validity = sum(m.validity_score * m.total_records for m in metrics_list) / total_records
        
        overall_score = (weighted_completeness + weighted_accuracy + weighted_consistency + weighted_validity) / 4
        
        return QualityMetrics(
            completeness_score=round(weighted_completeness, 3),
            accuracy_score=round(weighted_accuracy, 3),
            consistency_score=round(weighted_consistency, 3),
            validity_score=round(weighted_validity, 3),
            overall_score=round(overall_score, 3),
            total_records=total_records,
            valid_records=sum(m.valid_records for m in metrics_list),
            issue_count=sum(m.issue_count for m in metrics_list)
        )
    
    def _generate_recommendations(self, issues: List[QualityIssue], metrics: QualityMetrics) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºæ•´ä½“è´¨é‡åˆ†æ•°çš„å»ºè®®
        if metrics.overall_score < self.quality_thresholds['poor']:
            recommendations.append("æ•°æ®è´¨é‡è¾ƒå·®ï¼Œå»ºè®®å…¨é¢æ£€æŸ¥æ•°æ®å½•å…¥æµç¨‹")
        elif metrics.overall_score < self.quality_thresholds['acceptable']:
            recommendations.append("æ•°æ®è´¨é‡éœ€è¦æ”¹è¿›ï¼Œé‡ç‚¹å…³æ³¨é«˜ä¸¥é‡æ€§é—®é¢˜")
        elif metrics.overall_score < self.quality_thresholds['good']:
            recommendations.append("æ•°æ®è´¨é‡åŸºæœ¬å¯æ¥å—ï¼Œå»ºè®®æŒç»­ä¼˜åŒ–")
        else:
            recommendations.append("æ•°æ®è´¨é‡è‰¯å¥½ï¼Œä¿æŒç°æœ‰æµç¨‹")
        
        # åŸºäºå…·ä½“é—®é¢˜çš„å»ºè®®
        critical_issues = [i for i in issues if i.severity == 'critical']
        high_issues = [i for i in issues if i.severity == 'high']
        
        if critical_issues:
            recommendations.append(f"ç´§æ€¥å¤„ç† {len(critical_issues)} ä¸ªä¸¥é‡é—®é¢˜")
        
        if high_issues:
            recommendations.append(f"ä¼˜å…ˆå¤„ç† {len(high_issues)} ä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜")
        
        # åŸºäºé—®é¢˜ç±»å‹çš„å»ºè®®
        issue_types = {}
        for issue in issues:
            issue_types[issue.issue_type] = issue_types.get(issue.issue_type, 0) + 1
        
        if 'missing_data' in issue_types:
            recommendations.append("åŠ å¼ºæ•°æ®å½•å…¥çš„å®Œæ•´æ€§æ£€æŸ¥")
        
        if 'duplicate_records' in issue_types:
            recommendations.append("å»ºç«‹é‡å¤æ•°æ®æ£€æµ‹å’Œæ¸…ç†æœºåˆ¶")
        
        if 'business_rule_violation' in issue_types:
            recommendations.append("æ£€æŸ¥å’Œå®Œå–„ä¸šåŠ¡è§„åˆ™è¿‡æ»¤é€»è¾‘")
        
        return recommendations
    
    def export_report(self, report: QualityReport, format: str = 'json') -> str:
        """å¯¼å‡ºè´¨é‡æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        if format.lower() == 'json':
            filename = f"data_quality_report_{timestamp}.json"
            
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸
            report_dict = {
                'report_id': report.report_id,
                'timestamp': report.timestamp,
                'metrics': asdict(report.metrics),
                'issues': [asdict(issue) for issue in report.issues],
                'recommendations': report.recommendations,
                'data_sources': report.data_sources,
                'processing_time': report.processing_time
            }
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(report_dict, f, ensure_ascii=False, indent=2)
            
        elif format.lower() == 'html':
            filename = f"data_quality_report_{timestamp}.html"
            html_content = self._generate_html_report(report)
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(html_content)
        
        self.logger.info(f"è´¨é‡æŠ¥å‘Šå·²å¯¼å‡º: {filename}")
        return filename
    
    def _generate_html_report(self, report: QualityReport) -> str:
        """ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Š"""
        html = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>æ•°æ®è´¨é‡æŠ¥å‘Š - {report.report_id}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .metrics {{ display: flex; justify-content: space-around; margin: 20px 0; }}
                .metric {{ text-align: center; padding: 10px; border: 1px solid #ddd; border-radius: 5px; }}
                .issues {{ margin: 20px 0; }}
                .issue {{ margin: 10px 0; padding: 10px; border-left: 4px solid #ccc; }}
                .critical {{ border-left-color: #d32f2f; }}
                .high {{ border-left-color: #f57c00; }}
                .medium {{ border-left-color: #fbc02d; }}
                .low {{ border-left-color: #388e3c; }}
                .recommendations {{ background-color: #e8f5e8; padding: 15px; border-radius: 5px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>æ•°æ®è´¨é‡æŠ¥å‘Š</h1>
                <p><strong>æŠ¥å‘ŠID:</strong> {report.report_id}</p>
                <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {report.timestamp}</p>
                <p><strong>å¤„ç†æ—¶é—´:</strong> {report.processing_time:.2f} ç§’</p>
            </div>
            
            <div class="metrics">
                <div class="metric">
                    <h3>æ•´ä½“è´¨é‡</h3>
                    <p>{report.metrics.overall_score:.1%}</p>
                </div>
                <div class="metric">
                    <h3>å®Œæ•´æ€§</h3>
                    <p>{report.metrics.completeness_score:.1%}</p>
                </div>
                <div class="metric">
                    <h3>å‡†ç¡®æ€§</h3>
                    <p>{report.metrics.accuracy_score:.1%}</p>
                </div>
                <div class="metric">
                    <h3>ä¸€è‡´æ€§</h3>
                    <p>{report.metrics.consistency_score:.1%}</p>
                </div>
                <div class="metric">
                    <h3>æœ‰æ•ˆæ€§</h3>
                    <p>{report.metrics.validity_score:.1%}</p>
                </div>
            </div>
            
            <h2>è´¨é‡é—®é¢˜ ({len(report.issues)} ä¸ª)</h2>
            <div class="issues">
        """
        
        for issue in report.issues:
            html += f"""
                <div class="issue {issue.severity}">
                    <h4>{issue.issue_type} - {issue.severity.upper()}</h4>
                    <p><strong>æè¿°:</strong> {issue.description}</p>
                    <p><strong>å½±å“è®°å½•:</strong> {issue.affected_records}</p>
                    <p><strong>å»ºè®®æ“ä½œ:</strong> {issue.suggested_action}</p>
                </div>
            """
        
        html += f"""
            </div>
            
            <h2>æ”¹è¿›å»ºè®®</h2>
            <div class="recommendations">
                <ul>
        """
        
        for rec in report.recommendations:
            html += f"<li>{rec}</li>"
        
        html += """
                </ul>
            </div>
        </body>
        </html>
        """
        
        return html
    
    def print_summary(self, report: QualityReport):
        """æ‰“å°æŠ¥å‘Šæ‘˜è¦"""
        print("\n" + "=" * 80)
        print("æ•°æ®è´¨é‡ç›‘æ§æŠ¥å‘Šæ‘˜è¦")
        print("=" * 80)
        print(f"æŠ¥å‘ŠID: {report.report_id}")
        print(f"ç”Ÿæˆæ—¶é—´: {report.timestamp}")
        print(f"å¤„ç†æ—¶é—´: {report.processing_time:.2f} ç§’")
        print(f"æ•°æ®æº: {', '.join(report.data_sources)}")
        
        print(f"\nè´¨é‡æŒ‡æ ‡:")
        print(f"  æ•´ä½“è´¨é‡: {report.metrics.overall_score:.1%}")
        print(f"  å®Œæ•´æ€§: {report.metrics.completeness_score:.1%}")
        print(f"  å‡†ç¡®æ€§: {report.metrics.accuracy_score:.1%}")
        print(f"  ä¸€è‡´æ€§: {report.metrics.consistency_score:.1%}")
        print(f"  æœ‰æ•ˆæ€§: {report.metrics.validity_score:.1%}")
        
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»è®°å½•æ•°: {report.metrics.total_records:,}")
        print(f"  æœ‰æ•ˆè®°å½•æ•°: {report.metrics.valid_records:,}")
        print(f"  é—®é¢˜æ•°é‡: {report.metrics.issue_count}")
        
        # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡é—®é¢˜
        severity_counts = {}
        for issue in report.issues:
            severity_counts[issue.severity] = severity_counts.get(issue.severity, 0) + 1
        
        if severity_counts:
            print(f"\né—®é¢˜åˆ†å¸ƒ:")
            for severity in ['critical', 'high', 'medium', 'low']:
                if severity in severity_counts:
                    print(f"  {severity.upper()}: {severity_counts[severity]}")
        
        print(f"\næ”¹è¿›å»ºè®®:")
        for i, rec in enumerate(report.recommendations, 1):
            print(f"  {i}. {rec}")
        
        print("=" * 80)


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("æ•°æ®è´¨é‡ç›‘æ§ç³»ç»Ÿ v1.0")
    print("=" * 80)
    
    try:
        # åˆ›å»ºç›‘æ§å™¨
        monitor = DataQualityMonitor()
        
        # è¿è¡Œè´¨é‡æ£€æŸ¥
        report = monitor.run_quality_check()
        
        # æ‰“å°æ‘˜è¦
        monitor.print_summary(report)
        
        # å¯¼å‡ºæŠ¥å‘Š
        json_file = monitor.export_report(report, 'json')
        html_file = monitor.export_report(report, 'html')
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"  JSONæ ¼å¼: {json_file}")
        print(f"  HTMLæ ¼å¼: {html_file}")
        
    except Exception as e:
        logger.error(f"æ•°æ®è´¨é‡ç›‘æ§å¤±è´¥: {e}")
        print(f"\nâŒ ç›‘æ§å¤±è´¥: {e}")
    
    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()