import pandas as pd
import sqlite3
import numpy as np
from sqlalchemy import create_engine
import os

def inspect_excel_files():
    """
    Ê£ÄÊü•ExcelÊñá‰ª∂ÁöÑÂàóÁªìÊûÑÔºåÂ∏ÆÂä©ËØäÊñ≠Êï∞ÊçÆÂØºÂÖ•ÈóÆÈ¢ò
    """
    excel_files = {
        'inbound': 'ExcelÊñá‰ª∂Â§π/‰∫ßÊàêÂìÅÂÖ•Â∫ìÂàóË°®.xlsx',
        'summary': 'ExcelÊñá‰ª∂Â§π/Êî∂ÂèëÂ≠òÊ±áÊÄªË°®Êü•ËØ¢.xlsx',
        'sales': 'ExcelÊñá‰ª∂Â§π/ÈîÄÂîÆÂèëÁ•®ÊâßË°åÊü•ËØ¢.xlsx',
    }

    for file_type, file_path in excel_files.items():
        if os.path.exists(file_path):
            print(f"\n=== {file_type.upper()} FILE: {file_path} ===")
            try:
                df = pd.read_excel(file_path, sheet_name=0)
                print(f"Shape: {df.shape}")
                print(f"Columns: {list(df.columns)}")
                print(f"First few rows:")
                print(df.head(3))
                print(f"Data types:")
                print(df.dtypes)
            except Exception as e:
                print(f"Error reading {file_path}: {e}")
        else:
            print(f"File not found: {file_path}")
    print("\n" + "="*80)

# --- ÈÖçÁΩÆ ---
# ËØ∑ÊõøÊç¢‰∏∫ÊÇ®ÁöÑExcelÊñá‰ª∂Ë∑ØÂæÑÔºåÁ°Æ‰øùËøô‰∫õÊñá‰ª∂Âú® 'ExcelÊñá‰ª∂Â§π' ÂÜÖ
EXCEL_FILES = {
    'inbound': 'ExcelÊñá‰ª∂Â§π/‰∫ßÊàêÂìÅÂÖ•Â∫ìÂàóË°®.xlsx',
    'summary': 'ExcelÊñá‰ª∂Â§π/Êî∂ÂèëÂ≠òÊ±áÊÄªË°®Êü•ËØ¢.xlsx',
    'sales': 'ExcelÊñá‰ª∂Â§π/ÈîÄÂîÆÂèëÁ•®ÊâßË°åÊü•ËØ¢.xlsx',
    # Â¶ÇÊûúÊúâÂÖ∂‰ªñExcelÊñá‰ª∂Ôºå‰πüÂèØ‰ª•Âú®ËøôÈáåÊ∑ªÂä†
}
DB_NAME = 'temp_db.sqlite'                 # ‰∏¥Êó∂SQLiteÊï∞ÊçÆÂ∫ìÊñá‰ª∂Âêç
SQL_OUTPUT_FILE = 'import_data.sql'        # ÊúÄÁªàÁîüÊàêÁöÑSQLÊñá‰ª∂Âêç
DB_TABLE_PRODUCTS = 'Products'
DB_TABLE_METRICS = 'DailyMetrics'

def apply_inventory_data_filters(inventory_df):
    """
    Â∫îÁî®Â∫ìÂ≠òÊï∞ÊçÆËøáÊª§ÈÄªËæëÔºåÂèÇËÄÉÂéüÂßãPythonËÑöÊú¨‰∏≠ÁöÑdata_loader.py
    """
    if inventory_df.empty:
        return inventory_df

    print(f"  üìä Applying inventory data filters (original shape: {inventory_df.shape})")

    # Âà†Èô§ÂÖ®Á©∫Ë°åÂíåÂìÅÂêç‰∏∫Á©∫ÁöÑË°å
    inventory_df = inventory_df.dropna(how='all')
    inventory_df = inventory_df[inventory_df['Áâ©ÊñôÂêçÁß∞'].notna() & (inventory_df['Áâ©ÊñôÂêçÁß∞'] != '')]

    # Âú®ËøáÊª§Ââç‰øùÂ≠òÊâÄÊúâ"Âá§ËÇ†"‰∫ßÂìÅËÆ∞ÂΩïÔºå‰ª•‰æøÂêéÁª≠Ê∑ªÂä†ÂõûÊù•
    feng_chang_products = inventory_df[inventory_df['Áâ©ÊñôÂêçÁß∞'].astype(str).str.contains('Âá§ËÇ†', case=False, na=False)].copy()
    if not feng_chang_products.empty:
        print(f"  üîç Found {len(feng_chang_products)} Âá§ËÇ† products, will preserve after filtering")

    # ËøáÊª§ÊéâÂÆ¢Êà∑‰∏∫"ÂâØ‰∫ßÂìÅ"„ÄÅ"È≤úÂìÅ"ÊàñÁ©∫ÁôΩÁöÑËÆ∞ÂΩï
    if 'ÂÆ¢Êà∑' in inventory_df.columns:
        original_count = len(inventory_df)
        inventory_df['ÂÆ¢Êà∑'] = inventory_df['ÂÆ¢Êà∑'].astype(str).str.strip()
        excluded_customers = ['ÂâØ‰∫ßÂìÅ', 'È≤úÂìÅ', '']
        mask = ~inventory_df['ÂÆ¢Êà∑'].isin(excluded_customers)
        inventory_df = inventory_df[mask]
        print(f"  üö´ Excluded customers (ÂâØ‰∫ßÂìÅ, È≤úÂìÅ, empty): {original_count} ‚Üí {len(inventory_df)} records")

    # Ê†πÊçÆ"Áâ©ÊñôÂàÜÁ±ªÂêçÁß∞"ÂàóËøõË°åÁ≠õÈÄâ
    material_category_col = 'Áâ©ÊñôÂàÜÁ±ªÂêçÁß∞'
    if material_category_col in inventory_df.columns:
        excluded_categories = ['ÂâØ‰∫ßÂìÅ', 'ÁîüÈ≤úÂìÅÂÖ∂‰ªñ']
        inventory_df[material_category_col] = inventory_df[material_category_col].replace(r'^\s*$', np.nan, regex=True)

        mask = ~(
            inventory_df[material_category_col].isin(excluded_categories) |
            inventory_df[material_category_col].isna()
        )
        original_count = len(inventory_df)
        inventory_df = inventory_df[mask]
        print(f"  üö´ Excluded material categories (ÂâØ‰∫ßÂìÅ, ÁîüÈ≤úÂìÅÂÖ∂‰ªñ, empty): {original_count} ‚Üí {len(inventory_df)} records")

    # ÊéíÈô§Áâ©ÊñôÂêçÁß∞Âê´"È≤ú"Â≠óÁöÑËÆ∞ÂΩï
    original_count = len(inventory_df)
    inventory_df = inventory_df[~inventory_df['Áâ©ÊñôÂêçÁß∞'].astype(str).str.contains('È≤ú', case=False, na=False)]
    print(f"  üö´ Excluded products containing 'È≤ú': {original_count} ‚Üí {len(inventory_df)} records")

    # ÁâπÊÆäÂ§ÑÁêÜÔºöÂ∞Ü"Âá§ËÇ†"‰∫ßÂìÅÊ∑ªÂä†ÂõûÊù•
    if not feng_chang_products.empty:
        feng_chang_to_add = feng_chang_products[~feng_chang_products['Áâ©ÊñôÂêçÁß∞'].isin(inventory_df['Áâ©ÊñôÂêçÁß∞'])]
        if not feng_chang_to_add.empty:
            inventory_df = pd.concat([inventory_df, feng_chang_to_add], ignore_index=True)
            print(f"  ‚úÖ Re-added {len(feng_chang_to_add)} Âá§ËÇ† products back to inventory data")

    print(f"  ‚úÖ Inventory filtering complete: final shape {inventory_df.shape}")
    return inventory_df

def apply_production_data_filters(production_df):
    """
    Â∫îÁî®Áîü‰∫ßÊï∞ÊçÆËøáÊª§ÈÄªËæëÔºåÂèÇËÄÉÂéüÂßãPythonËÑöÊú¨‰∏≠ÁöÑdata_loader.py
    """
    if production_df.empty:
        return production_df

    print(f"  üìä Applying production data filters (original shape: {production_df.shape})")

    # Âà†Èô§ÂÖ®Á©∫Ë°å
    production_df = production_df.dropna(how='all')

    # Êï∞ÊçÆÊ∏ÖÊ¥óÔºöÂéªÈô§Áâ©ÊñôÂêçÁß∞‰∏≠Âê´"È≤ú"Â≠óÁöÑË°å
    if 'product_name' in production_df.columns:
        original_count = len(production_df)
        production_df = production_df[~production_df['product_name'].astype(str).str.contains('È≤ú', case=False, na=False)]
        print(f"  üö´ Excluded products containing 'È≤ú': {original_count} ‚Üí {len(production_df)} records")

    print(f"  ‚úÖ Production filtering complete: final shape {production_df.shape}")
    return production_df

def apply_sales_data_filters(sales_df):
    """
    Â∫îÁî®ÈîÄÂîÆÊï∞ÊçÆËøáÊª§ÈÄªËæëÔºåÂèÇËÄÉÂéüÂßãPythonËÑöÊú¨‰∏≠ÁöÑdata_loader.py
    """
    if sales_df.empty:
        return sales_df

    print(f"  üìä Applying sales data filters (original shape: {sales_df.shape})")

    # Ê∏ÖÊ¥óÊù°‰ª∂ 1: Áâ©ÊñôÂàÜÁ±ªÂàóÔºåÂéªÈô§"ÂâØ‰∫ßÂìÅ"„ÄÅ"Á©∫ÁôΩ"ÁöÑË°å
    material_category_column = 'Áâ©ÊñôÂàÜÁ±ª'
    if material_category_column in sales_df.columns:
        original_count = len(sales_df)
        sales_df[material_category_column] = sales_df[material_category_column].replace(r'^\s*$', np.nan, regex=True)
        sales_df = sales_df[
            (~sales_df[material_category_column].astype(str).str.lower().isin(['ÂâØ‰∫ßÂìÅ', 'nan', '']))
        ]
        print(f"  üö´ Excluded material categories (ÂâØ‰∫ßÂìÅ, empty): {original_count} ‚Üí {len(sales_df)} records")

    # Ê∏ÖÊ¥óÊù°‰ª∂ 2: ÂÆ¢Êà∑ÂêçÁß∞ÂàóÔºåÊéíÈô§ÂÆ¢Êà∑ÂêçÁß∞‰∏∫Á©∫„ÄÅ"ÂâØ‰∫ßÂìÅ"Êàñ"È≤úÂìÅ"ÁöÑËÆ∞ÂΩï
    customer_name_column = 'ÂÆ¢Êà∑ÂêçÁß∞'
    if customer_name_column in sales_df.columns:
        original_count = len(sales_df)
        sales_df[customer_name_column] = sales_df[customer_name_column].fillna('').astype(str).str.strip()
        excluded_customer_names_lower = ['', 'ÂâØ‰∫ßÂìÅ'.lower(), 'È≤úÂìÅ'.lower()]
        sales_df = sales_df[~sales_df[customer_name_column].str.lower().isin(excluded_customer_names_lower)]
        print(f"  üö´ Excluded customers (empty, ÂâØ‰∫ßÂìÅ, È≤úÂìÅ): {original_count} ‚Üí {len(sales_df)} records")

    # Ê∏ÖÊ¥óÊù°‰ª∂ 3: Áâ©ÊñôÂêçÁß∞ÂàóÔºåÂà†Èô§ÂÖ∂‰∏≠ÂåÖÂê´"È≤ú"ÁöÑËÆ∞ÂΩï
    if 'product_name' in sales_df.columns:
        original_count = len(sales_df)
        sales_df = sales_df[
            ~sales_df['product_name'].astype(str).str.contains('È≤ú', case=False, na=False)
        ]
        print(f"  üö´ Excluded products containing 'È≤ú': {original_count} ‚Üí {len(sales_df)} records")

    print(f"  ‚úÖ Sales filtering complete: final shape {sales_df.shape}")
    return sales_df

def clean_and_load_excel(file_path, file_type, sheet_name=0):
    """
    ËØªÂèñExcelÊñá‰ª∂Âπ∂ËøõË°åÂàùÊ≠•Ê∏ÖÊ¥ó„ÄÇ
    Ê≠§ÂáΩÊï∞Ê†πÊçÆÊñá‰ª∂Á±ªÂûãË∞ÉÊï¥ÂàóÂêçÔºåÂπ∂Â∞ÜÊó•ÊúüËΩ¨Êç¢‰∏∫YYYY-MM-DDÊ†ºÂºè„ÄÇ
    ÂÆûÁé∞‰∏éÂéüÂßãPythonËÑöÊú¨Áõ∏ÂêåÁöÑÊï∞ÊçÆËøáÊª§ÈÄªËæë„ÄÇ
    """
    print(f"Reading data from {file_path}...")
    df = pd.read_excel(file_path, sheet_name=sheet_name)

    print(f"  Original shape: {df.shape}")
    print(f"  Available columns: {list(df.columns)}")

    # Ê†πÊçÆÊñá‰ª∂Á±ªÂûãÈáçÂëΩÂêçÂàó
    if file_type == 'inbound':
        df.rename(columns={'ÂçïÊçÆÊó•Êúü': 'record_date', 'Áâ©ÊñôÂêçÁß∞': 'product_name', '‰∏ªÊï∞Èáè': 'production_volume'}, inplace=True)
        print(f"  Mapped columns: record_date, product_name, production_volume")

        # ‰øÆÂ§çÔºöÂ∞Ü‰∫ßÈáè‰ªéÂÖ¨Êñ§(kg)ËΩ¨Êç¢‰∏∫Âê®(t)
        if 'production_volume' in df.columns:
            df['production_volume'] = df['production_volume'] / 1000

        # Â∫îÁî®Áîü‰∫ßÊï∞ÊçÆËøáÊª§ÈÄªËæëÔºàÂèÇËÄÉÂéüÂßãPythonËÑöÊú¨Ôºâ
        df = apply_production_data_filters(df)

    elif file_type == 'summary':
        # Â∫îÁî®Â∫ìÂ≠òÊï∞ÊçÆËøáÊª§ÈÄªËæëÔºàÂèÇËÄÉÂéüÂßãPythonËÑöÊú¨Ôºâ
        df = apply_inventory_data_filters(df)

        df.rename(columns={'Áâ©ÊñôÂêçÁß∞': 'product_name', 'ÁªìÂ≠ò': 'inventory_level'}, inplace=True)
        print(f"  Mapped columns: product_name, inventory_level")

        # ‰∏∫Â∫ìÂ≠òÊï∞ÊçÆÂàõÂª∫Â§ö‰∏™Êó•ÊúüËÆ∞ÂΩïÔºåËÄå‰∏çÊòØÂè™Áî®‰∏Ä‰∏™Êñá‰ª∂‰øÆÊîπÊó•Êúü
        if 'record_date' not in df.columns:
            print(f"  üîß FIXING: Creating inventory records for multiple dates...")
            # ÂàõÂª∫‰ªé2025-06-01Âà∞2025-06-26ÁöÑÊó•ÊúüËåÉÂõ¥
            date_range = pd.date_range(start='2025-06-01', end='2025-06-26', freq='D')

            # ‰∏∫ÊØè‰∏™‰∫ßÂìÅÂàõÂª∫Â§ö‰∏™Êó•ÊúüÁöÑËÆ∞ÂΩï
            expanded_records = []
            for _, row in df.iterrows():
                for date in date_range:
                    new_row = row.copy()
                    new_row['record_date'] = date.strftime('%Y-%m-%d')
                    expanded_records.append(new_row)

            df = pd.DataFrame(expanded_records)
            print(f"  ‚úÖ Created {len(df)} inventory records across {len(date_range)} dates")

    elif file_type == 'sales':
        # Â∫îÁî®ÈîÄÂîÆÊï∞ÊçÆËøáÊª§ÈÄªËæëÔºàÂèÇËÄÉÂéüÂßãPythonËÑöÊú¨Ôºâ
        df = apply_sales_data_filters(df)

        # Ê£ÄÊü•ÂÆûÈôÖÁöÑ‰ª∑Ê†ºÂàóÂêç
        price_columns = [col for col in df.columns if 'Âçï‰ª∑' in col or '‰ª∑Ê†º' in col]
        print(f"  Available price columns: {price_columns}")

        # Â∞ùËØïÂ§öÁßç‰ª∑Ê†ºÂàóÊò†Â∞Ñ
        if 'Êú¨Â∏ÅÂê´Á®éÂçï‰ª∑' in df.columns:
            df.rename(columns={'ÂèëÁ•®Êó•Êúü': 'record_date', 'Áâ©ÊñôÂêçÁß∞': 'product_name', '‰∏ªÊï∞Èáè': 'sales_volume', 'Êú¨Â∏ÅÂê´Á®éÂçï‰ª∑': 'average_price'}, inplace=True)
            print(f"  Using 'Êú¨Â∏ÅÂê´Á®éÂçï‰ª∑' for price data")
        elif 'Âê´Á®éÂçï‰ª∑' in df.columns:
            df.rename(columns={'ÂèëÁ•®Êó•Êúü': 'record_date', 'Áâ©ÊñôÂêçÁß∞': 'product_name', '‰∏ªÊï∞Èáè': 'sales_volume', 'Âê´Á®éÂçï‰ª∑': 'average_price'}, inplace=True)
            print(f"  Using 'Âê´Á®éÂçï‰ª∑' for price data")
        elif 'Êú¨Â∏ÅÊó†Á®éÂçï‰ª∑' in df.columns and 'Êú¨Â∏ÅÊó†Á®éÈáëÈ¢ù' in df.columns:
            # ËÆ°ÁÆóÂê´Á®é‰ª∑Ê†º: (Êó†Á®éÈáëÈ¢ù / ‰∏ªÊï∞Èáè) * 1.09
            df.rename(columns={'ÂèëÁ•®Êó•Êúü': 'record_date', 'Áâ©ÊñôÂêçÁß∞': 'product_name', '‰∏ªÊï∞Èáè': 'sales_volume'}, inplace=True)
            # ‰øÆÂ§çÔºö‰ª∑Ê†ºÂçï‰Ωç‰ªé ÂÖÉ/ÂÖ¨Êñ§ ËΩ¨Êç¢‰∏∫ ÂÖÉ/Âê®
            df['average_price'] = (df['Êú¨Â∏ÅÊó†Á®éÈáëÈ¢ù'] / df['sales_volume']) * 1.09 * 1000
            print(f"  Calculated price from (Êó†Á®éÈáëÈ¢ù/‰∏ªÊï∞Èáè*1.09*1000) to get price in Yuan/Ton")
        else:
            df.rename(columns={'ÂèëÁ•®Êó•Êúü': 'record_date', 'Áâ©ÊñôÂêçÁß∞': 'product_name', '‰∏ªÊï∞Èáè': 'sales_volume'}, inplace=True)
            df['average_price'] = 0
            print(f"  ‚ö†Ô∏è  No suitable price column found, using 0")

    # Á°Æ‰øùÊó•ÊúüÊ†ºÂºèÁªü‰∏Ä‰∏∫ 'YYYY-MM-DD'
    if 'record_date' in df.columns:
        # Convert to datetime, coercing errors to NaT
        df['record_date'] = pd.to_datetime(df['record_date'], errors='coerce')
        # Drop rows where record_date is NaT (invalid date)
        before_count = len(df)
        df.dropna(subset=['record_date'], inplace=True)
        after_count = len(df)
        if before_count != after_count:
            print(f"  Dropped {before_count - after_count} rows with invalid dates")
        # Format to string
        df['record_date'] = df['record_date'].dt.strftime('%Y-%m-%d')
    else:
        print(f"  ‚ö†Ô∏è  Warning: No 'record_date' column found after renaming for {file_type} file.")

    # Á°Æ‰øù‰∫ßÂìÅÂêçÁß∞ÂàóÂ≠òÂú®Âπ∂Â§ÑÁêÜÂèØËÉΩÁöÑÂïÜÂìÅÂêçÁß∞Âà´Âêç
    if 'product_name' not in df.columns and 'ÂïÜÂìÅÂêçÁß∞' in df.columns:
        df.rename(columns={'ÂïÜÂìÅÂêçÁß∞': 'product_name'}, inplace=True)

    # ÂØπÊâÄÊúâÂÖ≥ÈîÆÊï∞ÂÄºÂàóËøõË°åÈùûÊï∞ÂÄºÂ§ÑÁêÜÔºà‰æãÂ¶ÇÔºåÂ∞Ü NaN ÊõøÊç¢‰∏∫ 0Ôºâ
    numeric_cols = [
        'production_volume', 'sales_volume', 'inventory_level', 'average_price'
    ]
    for col in numeric_cols:
        if col in df.columns:
            before_conversion = df[col].isna().sum()
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            after_conversion = (df[col] == 0).sum()
            print(f"  Column '{col}': {before_conversion} NaN values, {after_conversion} zero values after conversion")

    # --- Âçï‰ΩçËΩ¨Êç¢ ---
    # ‰øÆÂ§çÔºöÂ∞ÜÈîÄÈáèÂíå‰∫ßÈáè‰ªéÂÖ¨Êñ§(kg)ËΩ¨Êç¢‰∏∫Âê®(t)
    if 'sales_volume' in df.columns:
        print("  üîß CONVERTING: sales_volume from KG to Tons")
        df['sales_volume'] = df['sales_volume'] / 1000
    if 'production_volume' in df.columns:
        print("  üîß CONVERTING: production_volume from KG to Tons")
        df['production_volume'] = df['production_volume'] / 1000

    print(f"  Final shape: {df.shape}")
    return df

def main():
    # --- 1. ËØªÂèñÂπ∂ÂêàÂπ∂ÊâÄÊúâExcelÊï∞ÊçÆ ---
    all_data_frames = {}
    for key, path in EXCEL_FILES.items():
        all_data_frames[key] = clean_and_load_excel(path, key)

    # È¶ñÂÖàÔºå‰ªéÊâÄÊúâÊï∞ÊçÆ‰∏≠ÊèêÂèñÂîØ‰∏ÄÁöÑ‰∫ßÂìÅÂêçÁß∞
    unique_products = set()
    for df_key, df in all_data_frames.items():
        if 'product_name' in df.columns:
            unique_products.update(df['product_name'].unique())

    # ÂàõÂª∫‰∏Ä‰∏™‰∏¥Êó∂ÁöÑÂÜÖÂ≠òSQLiteÊï∞ÊçÆÂ∫ìËøûÊé•
    engine = create_engine(f'sqlite:///{DB_NAME}')
    conn = engine.connect()

    # --- 2. ÊèêÂèñÂπ∂ÊèíÂÖ•ÂîØ‰∏ÄÁöÑ‰∫ßÂìÅ‰ø°ÊÅØÂà∞ Products Ë°® ---
    print("Extracting unique products...")
    products_df = pd.DataFrame(list(unique_products), columns=['product_name'])
    # ÊâãÂä®ÂàÜÈÖç product_idÔºå‰ªé1ÂºÄÂßã
    products_df['product_id'] = products_df.index + 1
    
    products_df.to_sql(DB_TABLE_PRODUCTS, conn, if_exists='replace', index=False)
    print(f"{len(products_df)} unique products written to '{DB_TABLE_PRODUCTS}' table.")

    # Áõ¥Êé•‰ªé products_df ÂàõÂª∫Êò†Â∞ÑÔºåÂõ†‰∏∫ product_id Â∑≤ÁªèÊòéÁ°ÆÂàÜÈÖç
    product_name_to_id = products_df.set_index('product_name')['product_id'].to_dict()

    # --- 3. ÂáÜÂ§áÊØèÊó•ÊåáÊ†áÊï∞ÊçÆÂπ∂ÂÖ≥ËÅî‰∫ßÂìÅID ---
    print("Preparing daily metrics data...")
    # Êî∂ÈõÜÊâÄÊúâÊó•ÊúüÂíå‰∫ßÂìÅÁªÑÂêà
    all_dates = set()
    for df_key, df in all_data_frames.items():
        if 'record_date' in df.columns:
            dates_in_file = df['record_date'].unique()
            all_dates.update(dates_in_file)
            print(f"  {df_key} file has {len(dates_in_file)} unique dates: {sorted(dates_in_file)[:5]}...")

    print(f"  Total unique dates across all files: {len(all_dates)}")
    print(f"  Date range: {min(all_dates)} to {max(all_dates)}")

    # ÈÅçÂéÜÊØè‰∏™‰∫ßÂìÅÂíåÊó•ÊúüÔºåÂ∞ùËØïÂêàÂπ∂Êï∞ÊçÆ
    data_to_insert = []
    processed_combinations = 0

    for product_name in unique_products:
        # Ëé∑Âèñ‰∫ßÂìÅID
        product_id = product_name_to_id.get(product_name)
        if product_id is None:
            print(f"Warning: Product '{product_name}' not found in Products table. Skipping.")
            continue

        for record_date in sorted(list(all_dates)):
            production_volume = 0
            sales_volume = 0
            inventory_level = 0
            average_price = 0

            # ‰ªé 'inbound' Êñá‰ª∂Ëé∑ÂèñÁîü‰∫ßÈáè (ËÅöÂêàÂêå‰∏Ä‰∫ßÂìÅÂêå‰∏ÄÂ§©ÁöÑÊï∞ÊçÆ)
            inbound_df = all_data_frames.get('inbound')
            if inbound_df is not None and 'record_date' in inbound_df.columns and 'product_name' in inbound_df.columns:
                inbound_match = inbound_df[(inbound_df['record_date'] == record_date) & (inbound_df['product_name'] == product_name)]
                if not inbound_match.empty and 'production_volume' in inbound_match.columns:
                    production_volume = inbound_match['production_volume'].sum()  # ËÅöÂêàÂ§öÊù°ËÆ∞ÂΩï

            # ‰ªé 'sales' Êñá‰ª∂Ëé∑ÂèñÈîÄÂîÆÈáèÂíåÂùá‰ª∑ (ËÅöÂêàÂêå‰∏Ä‰∫ßÂìÅÂêå‰∏ÄÂ§©ÁöÑÊï∞ÊçÆ)
            sales_df = all_data_frames.get('sales')
            if sales_df is not None and 'record_date' in sales_df.columns and 'product_name' in sales_df.columns:
                sales_match = sales_df[(sales_df['record_date'] == record_date) & (sales_df['product_name'] == product_name)]
                if not sales_match.empty:
                    if 'sales_volume' in sales_match.columns:
                        sales_volume = sales_match['sales_volume'].sum()  # ËÅöÂêàÈîÄÂîÆÈáè
                    if 'average_price' in sales_match.columns:
                        # ËÆ°ÁÆóÂä†ÊùÉÂπ≥Âùá‰ª∑Ê†º
                        total_amount = (sales_match['sales_volume'] * sales_match['average_price']).sum()
                        total_volume = sales_match['sales_volume'].sum()
                        average_price = total_amount / total_volume if total_volume > 0 else 0

            # ‰ªé 'summary' Êñá‰ª∂Ëé∑ÂèñÂ∫ìÂ≠ò
            summary_df = all_data_frames.get('summary')
            if summary_df is not None and 'record_date' in summary_df.columns and 'product_name' in summary_df.columns:
                summary_match = summary_df[(summary_df['record_date'] == record_date) & (summary_df['product_name'] == product_name)]
                if not summary_match.empty and 'inventory_level' in summary_match.columns:
                    inventory_level = summary_match['inventory_level'].iloc[0]  # Â∫ìÂ≠òÈÄöÂ∏∏ÊòØÊúüÊú´‰ΩôÈ¢ù

            # Âè™ÊúâÂΩìËá≥Â∞ëÊúâ‰∏Ä‰∏™ÈùûÈõ∂ÂÄºÊó∂ÊâçÊèíÂÖ•ËÆ∞ÂΩï
            if production_volume > 0 or sales_volume > 0 or inventory_level > 0 or average_price > 0:
                data_to_insert.append({
                    'record_date': record_date,
                    'product_id': product_id,
                    'production_volume': production_volume,
                    'sales_volume': sales_volume,
                    'inventory_level': inventory_level,
                    'average_price': average_price
                })
                processed_combinations += 1

    print(f"  Created {processed_combinations} meaningful data records (non-zero values)")
    final_metrics_df = pd.DataFrame(data_to_insert)

    # --- 4. ‰ªé‰∏¥Êó∂Êï∞ÊçÆÂ∫ìÂØºÂá∫‰∏∫.sqlÊñá‰ª∂ ---
    print(f"Dumping database to {SQL_OUTPUT_FILE}...")
    with open(SQL_OUTPUT_FILE, 'w', encoding='utf-8') as f:
        # Ê∑ªÂä† schema.sql ÁöÑÂÜÖÂÆπÂà∞ÂØºÂÖ•ËÑöÊú¨‰∏≠Ôºå‰ª•Á°Æ‰øùË°®ÁªìÊûÑÂ≠òÂú®
        with open('backend/schema.sql', 'r', encoding='utf-8') as schema_f:
            f.write(schema_f.read())
            f.write('\n\n') # Ê∑ªÂä†Á©∫Ë°åÂàÜÈöî

        # Manually construct and write Products inserts with correct column order
        for index, row in products_df.iterrows():
            sql_values = (
                f"{row['product_id']},"
                f"'{row['product_name']}',"
                f"NULL,"  # sku
                f"NULL"   # category
            )
            f.write(f'INSERT INTO "Products" (product_id, product_name, sku, category) VALUES ({sql_values});\n')
        f.write('\n') # Add a newline after products inserts
        print(f"{len(products_df)} products written to SQL file.")

        # Manually construct and write DailyMetrics inserts
        if not final_metrics_df.empty:
            for index, row in final_metrics_df.iterrows():
                sql_values = (
                    f"'{row['record_date']}',"
                    f"{row['product_id']},"
                    f"{row['production_volume']},"
                    f"{row['sales_volume']},"
                    f"{row['inventory_level']},"
                    f"{row['average_price']}"
                )
                f.write(f'INSERT INTO "DailyMetrics" (record_date, product_id, production_volume, sales_volume, inventory_level, average_price) VALUES ({sql_values});\n')
            print(f"{len(final_metrics_df)} records written to '{DB_TABLE_METRICS}' table in SQL file.")
        else:
            print("No metrics data to write to SQL file.")


    print("SQL file generated successfully.")

    # --- 5. Ê∏ÖÁêÜ‰∏¥Êó∂Êï∞ÊçÆÂ∫ìÊñá‰ª∂ ---
    conn.close()
    if os.path.exists(DB_NAME):
        os.remove(DB_NAME)
        print(f"Temporary database file '{DB_NAME}' removed.")

    print("Process complete. You can now use wrangler to execute the .sql file:")
    print(f"npx wrangler d1 execute <YOUR_DB_NAME> --remote --file=./{SQL_OUTPUT_FILE}")

if __name__ == "__main__":
    # First inspect the Excel files to understand their structure
    print("üîç INSPECTING EXCEL FILES...")
    inspect_excel_files()

    # Ask user if they want to proceed with import
    proceed = input("\nüìã Do you want to proceed with data import? (y/n): ").lower().strip()
    if proceed == 'y':
        main()
    else:
        print("Import cancelled.")
